"""
Loss-функция / функция потерь нейронной сети ( функция ошибки) – математическая дифференцируемая функция,
характеризующая разницу между «истинным» значением целевой переменной и предсказанным нейронной сетью значением.

Актуально для такой нейронной сети, которая обучается с использованием обучающего набора (датасета),
который содержит примеры с истинными значениями: тегами, классами, показателями.
"""

import numpy as np
import tensorflow as tf


"""
Бинарная классификация (binary crossentropy BCE)

Это функция ошибок, которую можно использовать для количественной оценки разницы между двумя распределениями вероятностей.

Она говорит о том, что если у нас есть события и вероятности, насколько вероятно, что события произойдут на основе вероятностей?
Если это очень вероятно, у нас малая кросс-энтропия, а если маловероятно, у нас высокая кросс-энтропия.
"""


# При двоичной классификации каждая предсказанная вероятность сравнивается с фактическим значением класса (0 или 1),
# и вычисляется оценка, которая штрафует вероятность на основе расстояния от ожидаемого значения.

# !!! Используется в задачах бинарной классификации, в паре с функцией активации sigmoid

y_true = np.array([0, 0, 1, 0])
y_pred = np.array([0.02, 0.07, 0.9, 0.01])

bce_ = -((y_true * np.log(y_pred) + (1-y_true) * np.log(1 - y_pred))).sum()/len(y_true)
print(bce_) # 0.05204606291592068


# Проверим расчеты встроенными методами tensorflow:
tf.losses.binary_crossentropy(y_true, y_pred) # <tf.Tensor: shape=(), dtype=float64, numpy=0.05204595749369875>


# Пример использования бинарной кроссэнтропии в Keras'e:
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
model = Sequential()
model.add(Dense(64, input_shape=(10,), activation='softmax'))
model.compile(loss='binary_crossentropy', optimizer='adam')