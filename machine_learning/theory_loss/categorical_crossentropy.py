"""
Loss-функция / функция потерь нейронной сети ( функция ошибки) – математическая дифференцируемая функция,
характеризующая разницу между «истинным» значением целевой переменной и предсказанным нейронной сетью значением.

Актуально для такой нейронной сети, которая обучается с использованием обучающего набора (датасета),
который содержит примеры с истинными значениями: тегами, классами, показателями.
"""

import numpy as np
import tensorflow as tf



"""
Кросс-энтропия (categorical crossentropy ССЕ)

Кросс-энтропия (или логарифмическая функция потерь – log loss).

Кросс-энтропия измеряет расхождение между двумя вероятностными распределениями.
Если кросс-энтропия велика, это означает, что разница между двумя распределениями велика,
а если кросс-энтропия мала, то распределения похожи друг на друга.
"""

# !!! Используется в мультиклассовой классификации, в паре с функцией активации softmax

y_true = np.array([[0, 0, 1, 0], [1, 0, 0, 0]])
y_pred = np.array([[0.02, 0.07, 0.9, 0.01], [0.91, 0.03, 0.04, 0.02]])

y_true.shape # (2, 4)


# Посчитаем значение ошибки по указанной выше формуле:
cce_ = - sum(y_true * np.log(y_pred))
print(cce_) # [ 0.09431068 -0.    0.10536052 -0.]


# Проверим расчеты встроенными методами tensorflow:
tf.losses.categorical_crossentropy(y_true, y_pred) # <tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.10536052, 0.09431068])>



# Мы получили результирующий вектор из двух значений, поскольку входной набор состоит из двух элементов.
# Для получения результирующего значения ошибки нам необходимо получить среднее значение:

cce_ = sum(cce_) / len(cce_)
print(cce_) # 0.04991779878226689



# Пример использования категориальной кроссэнтропии в Keras'e:
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
model = Sequential()
model.add(Dense(64, input_shape=(10,), activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')
