"""
Функции активации

Определяют выходное значение нейрона в зависимости от результата взвешенной суммы входов и порогового значения.
Применяются к нейрону после того, просчитанному матричным умножением.
Определяет, передавать ли полученное значение следующему нейрону (активировать его) или нет, и модифицировать ли как-то полученное значение.



Рассмотрим нейрон, у которого взвешенная сумма равна z.

z = Σ (wi * xi + b)

wi - вес
xi - входное значение i-ого входа
b - смещение

Полученный результат передается в функцию активации, которая решает рассматривать этот нейрон как активированный, или его можно игнорировать.
"""


# Softmax - распределяет выходные значения пропорционально вероятности каждого из них в диапазоне ( 0;1 ); это означает, что сумма выходных значений всегда будет равна 1 (что эквивалентно 100% общей вероятности); данная функция хорошо подходит для задач по многоклассовой классификации.

# Вычисляется по программной формуле (Python), применимой к каждому входному вектору индивидуально:
# exp(x) / tf.reduce_sum(exp(x))

# Для многоклассовой классификацит используется функция softmax